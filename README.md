# ğŸ’¼ AI Job Scraper Pro

<div align="center">

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Maintenance](https://img.shields.io/badge/Maintained-Yes-brightgreen.svg)

**Automated job scraping tool that collects job postings from multiple Korean job sites and provides an interactive dashboard for analysis.**

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Demo](#-demo) â€¢ [Configuration](#%EF%B8%8F-configuration)

</div>

---

## ğŸ¯ Features

### ğŸ” Multi-Site Scraping
- **Saramin** (ì‚¬ëŒì¸) - Korea's leading job portal
- **JobKorea** (ì¡ì½”ë¦¬ì•„) - Comprehensive job listings
- Easily extendable to add more job sites

### ğŸ“Š Interactive Dashboard
- Real-time job statistics and analytics
- Advanced filtering (keyword, location, experience, date)
- Visual charts and graphs
- Export to CSV
- Mobile-responsive design

### ğŸ“§ Smart Notifications
- Email alerts for new job postings
- Daily summary reports
- Customizable notification rules
- HTML-formatted professional emails

### ğŸ’¾ Database Management
- SQLite database for efficient storage
- Automatic duplicate detection
- Historical data tracking
- Fast queries and indexing

### ğŸ¤– Automation Ready
- Async/await for high performance
- Cron job compatible
- Configurable scraping schedules
- Headless browser support

---

## ğŸš€ Installation

### Prerequisites
- Python 3.9 or higher
- pip package manager
- Git (for cloning)

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/ai-job-scraper.git
cd ai-job-scraper
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Install Playwright Browsers
```bash
playwright install chromium
```

### Step 5: Configure Environment Variables
```bash
# Copy the example file
cp .env.example .env

# Edit .env with your settings
# Required: Email credentials for notifications
```

---

## ğŸ’» Usage

### Basic Scraping

Run the scraper with default settings:
```bash
python scraper.py
```

### Custom Keywords
Edit the `scraper.py` file or create your own script:
```python
from scraper import JobScraper
import asyncio

scraper = JobScraper()
keywords = ["Python ê°œë°œì", "ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸", "ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´"]
asyncio.run(scraper.scrape_all(keywords=keywords, pages_per_site=5))
```

### Launch Dashboard
```bash
streamlit run dashboard.py
```

Then open your browser to `http://localhost:8501`

### Send Email Notifications
```python
from email_notifier import EmailNotifier
from scraper import JobScraper

scraper = JobScraper()
notifier = EmailNotifier()

# Scrape and notify
jobs = asyncio.run(scraper.scrape_saramin("Python", pages=3))
notifier.send_email(jobs)
```

---

## âš™ï¸ Configuration

### Email Settings (.env)

For Gmail users:
1. Enable 2-factor authentication on your Google account
2. Generate an App Password:
   - Go to Google Account â†’ Security
   - Under "Signing in to Google", select "App passwords"
   - Create a new app password for "Mail"
3. Use this app password in your `.env` file

```env
SENDER_EMAIL=your-email@gmail.com
SENDER_PASSWORD=your-16-digit-app-password
RECEIVER_EMAIL=alerts@yourdomain.com
```

### Scraping Configuration

Customize scraping behavior:
```python
# Number of pages per site
pages_per_site = 5

# Keywords to search
keywords = ["ê°œë°œì", "ì—”ì§€ë‹ˆì–´", "í”„ë¡œê·¸ë˜ë¨¸"]

# Headless mode (True for background, False to see browser)
headless = True
```

---

## ğŸ—‚ï¸ Project Structure

```
ai-job-scraper/
â”‚
â”œâ”€â”€ scraper.py              # Main scraping engine
â”œâ”€â”€ dashboard.py            # Streamlit web dashboard
â”œâ”€â”€ email_notifier.py       # Email notification system
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example           # Environment variables template
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ README.md              # This file
â”‚
â”œâ”€â”€ jobs.db                # SQLite database (created after first run)
â””â”€â”€ screenshots/           # Dashboard screenshots (optional)
```

---

## ğŸ“Š Database Schema

```sql
CREATE TABLE jobs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    company TEXT NOT NULL,
    location TEXT,
    salary TEXT,
    experience TEXT,
    education TEXT,
    url TEXT UNIQUE NOT NULL,
    source TEXT NOT NULL,
    posted_date TEXT,
    scraped_date TEXT NOT NULL,
    keywords TEXT
);
```

---

## ğŸ”„ Automation with Cron

### Linux/macOS

Edit crontab:
```bash
crontab -e
```

Add daily scraping at 9 AM:
```bash
0 9 * * * cd /path/to/ai-job-scraper && /path/to/venv/bin/python scraper.py
```

### Windows Task Scheduler

1. Open Task Scheduler
2. Create Basic Task
3. Set trigger (e.g., Daily at 9:00 AM)
4. Action: Start a program
5. Program: `C:\path\to\python.exe`
6. Arguments: `C:\path\to\scraper.py`

---

## ğŸ› ï¸ Troubleshooting

### Playwright Installation Issues
```bash
# Install specific browser
playwright install chromium

# Install system dependencies (Linux)
playwright install-deps
```

### Database Locked Error
```python
# Increase timeout in scraper.py
conn = sqlite3.connect('jobs.db', timeout=10.0)
```

### SMTP Authentication Error
- Verify app password (not regular password)
- Check 2FA is enabled
- Try "Less secure app access" if app passwords unavailable

### Scraping Failures
- Check internet connection
- Verify target website is accessible
- Some sites may have anti-scraping measures
- Add delays between requests if needed

---

## ğŸš€ Future Enhancements

- [ ] Support for more job sites (LinkedIn, Indeed, etc.)
- [ ] AI-powered job matching and recommendations
- [ ] Telegram bot integration
- [ ] Advanced analytics and trends
- [ ] Resume matching and scoring
- [ ] API endpoint for external integrations
- [ ] Docker containerization
- [ ] Cloud deployment guide

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## âš ï¸ Disclaimer

This tool is for educational and personal use only. Please:
- Respect website terms of service
- Don't overload servers with excessive requests
- Add appropriate delays between requests
- Use scraped data responsibly
- Comply with local data protection laws

---

## ğŸŒŸ Acknowledgments

- [Playwright](https://playwright.dev/) - Web automation framework
- [Streamlit](https://streamlit.io/) - Dashboard framework
- [Plotly](https://plotly.com/) - Interactive charts
- Korean job sites for providing valuable data

---

## ğŸ‘¤ About the Developer

**ianalp** - AI Automation & Full-Stack Developer

I specialize in creating intelligent automation solutions that save time and boost productivity.

### ğŸ› ï¸ Tech Stack

- **Backend:** Python, FastAPI, Node.js
- **Frontend:** React, Next.js, TypeScript
- **AI/ML:** OpenAI API, Claude API, LangChain
- **Automation:** Playwright, Selenium, Web Scraping
- **Data:** Pandas, SQL, Data Visualization

### ğŸ“« Contact

- ğŸ“§ **Email:** forplanai@gmail.com
- ğŸ”— **GitHub:** [github.com/ianalp](https://github.com/ianalp)
- ğŸ¦ **Twitter:** [@ianalp0914](https://twitter.com/ianalp0914)
- ğŸ’¼ **Kmong:** Available for freelance projects

### ğŸŒŸ Services

Looking for automation solutions? I can help with:

- ğŸ¤– Web Scraping & Data Collection
- ğŸ“Š Business Dashboards & Analytics
- âœï¸ AI-Powered Content Generation
- ğŸ”„ Workflow Automation
- ğŸ’» Custom Software Development

**Open for freelance projects!** Feel free to reach out.

---

<div align="center">

**Made with â¤ï¸ by [Chan Yeon Park](https://github.com/ianalp)**

â­ Star this repo if you find it useful!

</div>
